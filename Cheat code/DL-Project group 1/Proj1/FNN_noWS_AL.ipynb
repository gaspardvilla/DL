{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import dlc_practical_prologue      \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "size=1000;\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    dlc_practical_prologue.generate_pair_sets(size)\n",
    "train_input, train_target, train_classes = Variable(train_input), Variable(train_target), Variable((train_classes))\n",
    "test_input, test_target, test_classes = Variable(test_input), Variable(test_target), Variable(test_classes)\n",
    "mini_batch_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting 10 different test sets to verify each model against all of them\n",
    "#the test error will be the average of the 10 test errors I get\n",
    "test_input_10 = torch.Tensor(10, 2*size, 14*14)\n",
    "test_target_10 = torch.Tensor(10, size)\n",
    "test_classes_10 = torch.Tensor(10, 2*size)\n",
    "for i in range(1,10):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    dlc_practical_prologue.generate_pair_sets(size)\n",
    "    test_input, test_target, test_classes = Variable(test_input), Variable(test_target), Variable(test_classes)\n",
    "    test_input_10[i,:,:] = test_input.reshape([2*size,196])\n",
    "    test_target_10[i,:] = test_target\n",
    "    test_classes_10[i,:] = test_classes.reshape([2*size])\n",
    "my_train_input = train_input.reshape([2*size,196])\n",
    "my_train_classes = train_classes.reshape([2*size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying samples of data\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.imshow(test_input[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Value: {}\".format(test_classes[i][0]))  \n",
    "  plt.tight_layout()\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying samples of data\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.imshow(test_input[i][1], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Value: {}\".format(test_classes[i][1]))  \n",
    "  plt.tight_layout()\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First neural net\n",
    "Train the model on all the 2000 images in train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    dlc_practical_prologue.generate_pair_sets(size)\n",
    "train_input, train_target, train_classes = Variable(train_input), Variable(train_target), Variable((train_classes))\n",
    "test_input, test_target, test_classes = Variable(test_input), Variable(test_target), Variable(test_classes)\n",
    "\n",
    "my_train_input = train_input.reshape([2*size,196])\n",
    "my_train_classes = train_classes.reshape([2*size])\n",
    "\n",
    "my_train_input1 = train_input[:,0,:]\n",
    "my_train_input2 = train_input[:,1,:]\n",
    "my_train_classes1 = train_classes[0:size,0]\n",
    "my_train_classes2 = train_classes[0:size,1]\n",
    "\n",
    "my_test_input1 = test_input[:,0,:]\n",
    "my_test_input2 = test_input[:,1,:]\n",
    "my_test_classes1 = test_classes[0:size,0]\n",
    "my_test_classes2 = test_classes[0:size,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epoch\n",
    "num_epochs = 25\n",
    "# batch size to compute mini-batch\n",
    "batch_size = 100\n",
    "# number of pixels in the image \n",
    "input_size = 196\n",
    "# number of possible digit: 0 to 9 \n",
    "num_class = 2\n",
    "# small step to find a minima\n",
    "learning_rate = 0.001\n",
    "# hidden size\n",
    "hidden_size = 50\n",
    "# drop out\n",
    "dropout_p = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_based_on_imgs(model_, my_test_input1_, my_test_input2_, test_target_):\n",
    "    total = my_test_input1_.size(0)\n",
    "    out1, out2, result = model_(my_test_input1_, my_test_input2_, total)\n",
    "\n",
    "    _, predictions1 = torch.max(out1.data, 1)\n",
    "    _, predictions2 = torch.max(out2.data, 1)\n",
    "    predictions = (predictions1 <= predictions2).long()\n",
    "\n",
    "    well_predicted_count = (predictions == test_target_).sum().item()\n",
    "\n",
    "    return 1 - well_predicted_count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_based_on_result(model_, my_test_input1_, my_test_input2_, test_target_):\n",
    "    total = my_test_input1_.size(0)\n",
    "    out1, out2, result = model_(my_test_input1_, my_test_input2_, total)\n",
    "    _, predictions = torch.max(result.data, 1)\n",
    "    well_predicted_count = (predictions == test_target_).sum().item()\n",
    "    return 1 - well_predicted_count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_, my_train_input1_, my_train_input2_, my_test_classes1, my_test_classes2, train_target_, criterion_, optimizer_,num_epochs_,batch_size_):\n",
    "\n",
    "    train_error_based_on_imgs = []\n",
    "    train_error_based_on_result = []\n",
    "    test_error_based_on_imgs = []\n",
    "    test_error_based_on_result = []\n",
    "    # train function\n",
    "    \n",
    "    lambda_ = lambda epoch: 0.95 ** epoch\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer_, lr_lambda=lambda_)\n",
    "    \n",
    "    for epoch in range(1, num_epochs_+1):\n",
    "        for i in range(int(len(my_train_input1_)/batch_size_)):  \n",
    "            # Move tensors to the configured device\n",
    "            images1 = my_train_input1_.narrow(0,i*batch_size_,batch_size_)\n",
    "            images2 = my_train_input2_.narrow(0,i*batch_size_,batch_size_)\n",
    "            labels1 = my_test_classes1.narrow(0,i*batch_size_,batch_size_)\n",
    "            labels2 = my_test_classes2.narrow(0,i*batch_size_,batch_size_)\n",
    "            target_labels = train_target_.narrow(0,i*batch_size_,batch_size_)\n",
    "            \n",
    "            # Forward pass\n",
    "            out1, out2, result = model_(images1, images2, batch_size_)\n",
    "\n",
    "            loss1 = criterion_(out1, labels1)\n",
    "            loss2 = criterion_(out2, labels2)\n",
    "            loss3 = criterion_(result, target_labels)\n",
    "            real_loss = loss1 + loss2 + loss3\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer_.zero_grad()\n",
    "            real_loss.backward()\n",
    "            optimizer_.step()            \n",
    "\n",
    "\n",
    "        scheduler.step()\n",
    "    train_error_based_on_imgs.append(test_accuracy_based_on_imgs(model_, my_train_input1_, my_train_input2_, train_target))\n",
    "    train_error_based_on_result.append(test_accuracy_based_on_result(model_, my_train_input1_, my_train_input2_, train_target))\n",
    "    test_error_based_on_imgs.append(test_accuracy_based_on_imgs(model_, my_test_input1, my_test_input2, test_target))\n",
    "    test_error_based_on_result.append(test_accuracy_based_on_result(model_, my_test_input1, my_test_input2, test_target))\n",
    "\n",
    "    if(epoch == 25):    \n",
    "        print ('Loss: {:.4f} on epoch: {}, train error based on imgs and result: {:.5f}, {:.5f}; test error: {:.5f}, {:.5f}'.format(real_loss.item(),epoch,train_error_based_on_imgs[-1],train_error_based_on_result[-1],test_error_based_on_imgs[-1],test_error_based_on_result[-1]))\n",
    "    return train_error_based_on_imgs, train_error_based_on_result, test_error_based_on_imgs, test_error_based_on_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8851 on epoch: 25, train error based on imgs and result: 0.03600, 0.24200; test error: 0.14000, 0.28400\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_class):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU() \n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)  \n",
    "        self.layer3 = nn.Linear(hidden_size, 10) \n",
    "        \n",
    "        \n",
    "        self.layer1_ = nn.Linear(input_size, hidden_size) \n",
    "        self.layer2_ = nn.Linear(hidden_size, hidden_size)  \n",
    "        self.layer3_ = nn.Linear(hidden_size, 10) \n",
    "        \n",
    "        self.layer1_comp = nn.Linear(20, 200) \n",
    "        self.layer2_comp = nn.Linear(200, 200)  \n",
    "        self.layer3_comp = nn.Linear(200, 2)\n",
    "    \n",
    "    def forward(self, img1, img2, batch_size_images):\n",
    "        img1 = img1.reshape(batch_size_images,196)\n",
    "        out1 = self.layer1(img1)\n",
    "        out1 = self.relu(out1)\n",
    "        out1 = self.layer2(out1)\n",
    "        out1 = self.relu(out1)\n",
    "        out1 = self.layer3(out1)\n",
    "        \n",
    "        img2 = img2.reshape(batch_size_images,196)\n",
    "        out2 = self.layer1_(img2)\n",
    "        out2 = self.relu(out2)\n",
    "        out2 = self.layer2_(out2)\n",
    "        out2 = self.relu(out2)\n",
    "        out2 = self.layer3_(out2)\n",
    "\n",
    "        result = torch.cat((out1,out2), dim=1, out=None)\n",
    "        \n",
    "        result = self.layer1_comp(result)\n",
    "        result = self.relu(result)\n",
    "        result = self.layer2_comp(result)\n",
    "        result = self.relu(result)\n",
    "        result = self.layer3_comp(result)\n",
    "        \n",
    "        return out1, out2, result\n",
    "  \n",
    "# creating neural net\n",
    "model = NeuralNet(input_size, hidden_size, num_class)\n",
    "\n",
    "# CrossEntropyLoss and optimizer which minimize loss with learning rate step\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) \n",
    "\n",
    "train_error_based_on_imgs, train_error_based_on_result, test_error_based_on_imgs, test_error_based_on_result = train_model(model, my_train_input1, my_train_input2, my_train_classes1, my_train_classes2, train_target, criterion, optimizer, num_epochs, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.07700, 0.11900\n",
      "Loss: 0.0000 on epoch: 25, train error based on imgs and result: 0.00100, 0.00000; test error: 0.06900, 0.09500\n",
      "Loss: 0.0003 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.07000, 0.12100\n",
      "Loss: 0.0000 on epoch: 25, train error based on imgs and result: 0.00100, 0.00000; test error: 0.08400, 0.11600\n",
      "Loss: 0.0000 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.07100, 0.11100\n",
      "Loss: 0.0111 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.09500, 0.11500\n",
      "Loss: 0.0000 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.07300, 0.09900\n",
      "Loss: 0.0032 on epoch: 25, train error based on imgs and result: 0.00200, 0.00000; test error: 0.07900, 0.10500\n",
      "Loss: 0.0000 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.07300, 0.09100\n",
      "Loss: 0.0028 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.07700, 0.11300\n"
     ]
    }
   ],
   "source": [
    "train_img = []\n",
    "train_comp = []\n",
    "\n",
    "test_img = []\n",
    "test_comp = []\n",
    "\n",
    "for i in range(10):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    dlc_practical_prologue.generate_pair_sets(size)\n",
    "    train_input, train_target, train_classes = Variable(train_input), Variable(train_target), Variable((train_classes))\n",
    "    test_input, test_target, test_classes = Variable(test_input), Variable(test_target), Variable(test_classes)\n",
    "\n",
    "    my_train_input = train_input.reshape([2*size,196])\n",
    "    my_train_classes = train_classes.reshape([2*size])\n",
    "\n",
    "    my_train_input1 = train_input[:,0,:]\n",
    "    my_train_input2 = train_input[:,1,:]\n",
    "    my_train_classes1 = train_classes[0:size,0]\n",
    "    my_train_classes2 = train_classes[0:size,1]\n",
    "\n",
    "    my_test_input1 = test_input[:,0,:]\n",
    "    my_test_input2 = test_input[:,1,:]\n",
    "    my_test_classes1 = test_classes[0:size,0]\n",
    "    my_test_classes2 = test_classes[0:size,1]\n",
    "    # creating neural net\n",
    "    model = NeuralNet(input_size, hidden_size, num_class)\n",
    "\n",
    "    # CrossEntropyLoss and optimizer which minimize loss with learning rate step\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) \n",
    "\n",
    "    train_error_based_on_imgs, train_error_based_on_result, test_error_based_on_imgs, test_error_based_on_result = train_model(model, my_train_input1, my_train_input2, my_train_classes1, my_train_classes2, train_target, criterion, optimizer, num_epochs, 1)\n",
    "    train_img.append(train_error_based_on_imgs)\n",
    "    train_comp.append(train_error_based_on_result)\n",
    "    test_img.append(test_error_based_on_imgs)\n",
    "    test_comp.append(test_error_based_on_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007467261881037794\n",
      "0.009912113800799514\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.std(test_img))\n",
    "print(np.std(test_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07679999999999995\n",
      "0.1085\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(test_img))\n",
    "print(np.mean(test_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_error_based_on_imgs, 'r', train_error_based_on_result, 'r--', test_error_based_on_imgs, 'b', test_error_based_on_result, 'b--')\n",
    "plt.ylabel('some numbers')\n",
    "plt.title(\"Train error in red, test error in blue over the epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}\".format(1-min(test_error_based_on_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
