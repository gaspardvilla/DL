{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import dlc_practical_prologue      \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "size=1000;\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    dlc_practical_prologue.generate_pair_sets(size)\n",
    "train_input, train_target, train_classes = Variable(train_input), Variable(train_target), Variable((train_classes))\n",
    "test_input, test_target, test_classes = Variable(test_input), Variable(test_target), Variable(test_classes)\n",
    "mini_batch_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting 10 different test sets to verify each model against all of them\n",
    "#the test error will be the average of the 10 test errors I get\n",
    "test_input_10 = torch.Tensor(10, 2*size, 14*14)\n",
    "test_target_10 = torch.Tensor(10, size)\n",
    "test_classes_10 = torch.Tensor(10, 2*size)\n",
    "for i in range(1,10):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    dlc_practical_prologue.generate_pair_sets(size)\n",
    "    test_input, test_target, test_classes = Variable(test_input), Variable(test_target), Variable(test_classes)\n",
    "    test_input_10[i,:,:] = test_input.reshape([2*size,196])\n",
    "    test_target_10[i,:] = test_target\n",
    "    test_classes_10[i,:] = test_classes.reshape([2*size])\n",
    "my_train_input = train_input.reshape([2*size,196])\n",
    "my_train_classes = train_classes.reshape([2*size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying samples of data\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.imshow(test_input[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Value: {}\".format(test_classes[i][0]))  \n",
    "  plt.tight_layout()\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAELCAYAAAD3HtBMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFRVJREFUeJzt3X+Q1XW9x/HXW8B0lbICCUIhBISbAVcgcEZTZyhUCKgssJtON2UzB8xG6jbl2F7NtHE0B9ExGwIMpVRuGiIDIoIZU6OYRMJe8zrxI/kpQvyWH5/7x/musxKfz57zZs853+M+HzNndM/rfD/fz+5+OK/z3f2e71oIQQAAlOqEak8AAFCbKBAAgAsFAgBwoUAAAC4UCADAhQIBALi8LwvEzHqaWTCz9tWeC/KNtYJisE6OLZcFYmYLzeyWY9w/1sw25embaGb9zWyJme00s9fN7AvVnlNbUmNrZamZ7Tez3dntf6s9p7ailtZJEzPrk62X2dWeS0wuC0TSTElXmpkddf+Vkh4OIRyq/JT+VbbonpT0lKSPSKqXNNvM+lZ1Ym3LTNXAWmlmUgjh1Ox2drUn04bMVG2tE0m6T9KL1Z5ESl4L5AkVnpAvaLrDzD4sabSkh7KPR5nZn83sn2a23swaYoOZ2d/NbESzjxuat7qZDTez5Wa2w8xWmtlFRc6zn6Rukn4WQjgcQlgi6Q8qLEpURq2sFVRXTa0TM5sgaYekZ0vZrtJyWSAhhH2SHpV0VbO7vyKpMYSwMvt4T5afJmmUpG+Z2bhS92VmH5c0X9KPVVhgUyTNNbPOWf59M3sqtnnkvnNKnQd8amitNLndzLaZ2R8on8qppXViZh+UdIukG0vdd6XlskAysyR92cxOzj6+KrtPkhRCWBpCWBVCOBJC+IukOZIudOzna5KeDiE8nY31jKSXJF2W7eeOEMLoyLaNkrZI+q6ZdTCzz2VzqHPMA361sFYk6b8k9ZL0cUkPSppnZmc55gGfWlknt0qaHkJY79h3ReW2QEIIL0jaKmmsmfWSNFTSI025mQ0zs+fMbKuZ7ZR0raROjl31UGFR7Wi6STpfUtci5nhQ0jgVXq1sUuEVw6OSNjjmAadaWCvZPP8UQtgVQjgQQpilwo87L3PMAw61sE7MbJCkEZJ+5thvxeXuzIOjPKTCq4SzJS0KIWxulj0iaZqkS0MI+83sHsW/2Xv03qOCjzX7//WSfhVCmOiZYPZK5d1XKWa2XM1e1aBicr9WjiHo2D8GRfnkfZ1cJKmnpHXZ7/tPldTOzP4thHCuY7yyyu0RSOYhFdp4ov71SbmjpO3ZN/rTkr6aGOcVSROyHzMNkXR5s2y2pM+b2Ugza2dmJ5nZRWbWvZgJmtmAbJs6M5uiwquMmcV9emhFuV4rZnZatt1JZtbezP5D0mckLSzhc8Txy/U6UeFHm2dJGpTdHlDh9ykji/nkKi6EkOubpKWS3pb0gaPuv1zSWkm7VDiNdpqk2VnWU4VXd+2zj3tJ+pOk3Sp8M6Y2PTbLh0laJmm7Coe48yWdmWU/kLQgMb87s/ntlrRAUu9qf83a6i3Pa0VSZxVOydylwtk1f5T02Wp/zdriLc/r5BhzbWg+bt5ulk0SAICS5P1HWACAnKJAAAAuFAgAwIUCAQC4UCAAAJeS3khoZpyylUMhhFy9GY11klvbQgidqz2J5lgruVXUWuEIBGg71lZ7AqgZRa0VCgQA4EKBAABcKBAAgAsFAgBwoUAAAC4UCADAhQIBALhQIAAAFwoEAOBCgQAAXCgQAIALBQIAcCnparxALTrxxBOT+dChQ6PZ/v37o9m6deuS47711lvpiUUcOXLEtR2K09DQEM3uuuuu5La7du1q5dkUdO4cv/DtbbfdFs3q6+vLMZ2icQQCAHChQAAALhQIAMCFAgEAuFAgAAAXCgQA4PK+Po33O9/5TjT70Y9+FM1WrVqVHHfixInRrLGxseWJoaI6duyYzH//+99Hs9RpvJs2bUqOu3Zt/M9Kd+/ePZq9/PLL0eyHP/xhcp+vv/56Mm8runbtGs3OOOOMaLZ3795yTKdFd999dzSr1pyKwREIAMCFAgEAuFAgAAAXCgQA4EKBAABcKBAAgEvuT+NNnYK5aNGi5LbDhw937fP8889P5iNGjIhmnMZbHXV1ddFsxowZyW0ffPDBaHbzzTdHswEDBiTH7dSpUzTbvHlzNFuxYkU027dvX3KfKBg3blw0S33tDx8+XI7ptCj1PJfn5xSOQAAALhQIAMCFAgEAuFAgAAAXCgQA4EKBAABccn8a7xVXXBHNWjpNd8eOHdHs2WefjWZf+tKXkuOmTuOdNm1aclv49ejRI5qlrqjbrVu35LiDBg2KZlu2bIlmixcvTo6L6rnmmmui2WOPPVbBmRRn8ODB0ezJJ5+s4ExKwxEIAMCFAgEAuFAgAAAXCgQA4EKBAABcKBAAgAsFAgBwyf37QFLvuWjJqaeeGs2++MUvusedN2+ee1v4pc7t7969ezRLvR9Ikm699dZoNmfOnGj20ksvJcd94403kjnKp127dtWewnv069cvmafW77Jly1p7Oq2GIxAAgAsFAgBwoUAAAC4UCADAhQIBALhQIAAAl9yfxvuTn/wkmo0dOza57YknnujaZwghma9Zs8Y1Lo7P/fffH81S37OOHTsmx02d5tu3b99oduGFFybH/c1vfhPNnn/++eS2OD6HDh2KZgMGDIhmLa2V9u3jT5mpPzdQX1+fHPfIkSPRLM+ng3MEAgBwoUAAAC4UCADAhQIBALhQIAAAFwoEAOBiLZ2y+p4HmxX/4Aro2rVrMh82bFg0e+yxx6JZ6pQ6STrjjDOi2ZYtW5LblkMIwSq+04S8rZNy6dKlSzKfNWtWNLvkkktaezrFWBFCGFKNHceUa62kruL929/+NpqlruAtpU8Xf+edd6LZ4cOHk+OuXr06mg0dOjS5bZkUtVY4AgEAuFAgAAAXCgQA4EKBAABcKBAAgAsFAgBwoUAAAC65v5x7XV1dNNu4cWNy23bt2kWz1GWZH3jggeS41XivB/KnpfPzTznllArNBEdbvHhxNOvWrVs0a+m9Zdu2bYtm27dvj2bz589PjvvRj340mecVRyAAABcKBADgQoEAAFwoEACACwUCAHChQAAALrk/jXfv3r3ubcePH9+KM0GeXX/99dFs586dyW137NgRze68885o1qdPn+S4U6dOTeaojl27drmy47Fq1apkPnDgwLLst9w4AgEAuFAgAAAXCgQA4EKBAABcKBAAgAsFAgBwyf1pvMejf//+ru0WLVrUyjNBuS1dujSaLVy4MLltly5dotnWrVujWUNDQ3Lcu+66K5mj7Xj11VeT+bBhwyo0k9bFEQgAwIUCAQC4UCAAABcKBADgQoEAAFwoEACAi4UQin+wWfEPzoHJkydHs/r6+mh23nnnJcfdvXu3e07lEEKwas+hubytk169eiXz1CmUL7zwQjRbv369e05VsiKEMKTak2gub2sF7ypqrXAEAgBwoUAAAC4UCADAhQIBALhQIAAAFwoEAOBCgQAAXN7X7wNpK3gfCIrE+0BQLN4HAgAoHwoEAOBCgQAAXCgQAIALBQIAcKFAAAAu7Ut8/DZJa8sxEbj1qPYEjoF1kk+sFRSrqLVS0vtAAABowo+wAAAuFAgAwIUCAQC4UCAAABcKBADgQoEAAFwoEACACwUCAHChQAAALhQIAMCFAgEAuFAgAAAXCgQA4PK+LBAz62lmwcxKvVw92hDWCYrFWjm2XBaImS00s1uOcf9YM9uUp2+imc02s41m9k8ze83Mrqn2nNqKGlsn/c1siZntNLPXzewL1Z5TW1JLa0WSzGyCma0xsz1m9n9mdkG153QsuSwQSTMlXWlmdtT9V0p6OIRwqPJTirpdUs8QwgcljZH0YzMbXOU5tRUzVQPrJHtyelLSU5I+Iqle0mwz61vVibUtM1UDa0WSzOyzkn4q6T8ldZT0GUlvVHVSEXktkCdU+If2buua2YcljZb0UPbxKDP7c/bKf72ZNcQGM7O/m9mIZh83mNnsZh8PN7PlZrbDzFaa2UXFTjSE8GoI4UDTh9ntrGK3x3GplXXST1I3ST8LIRwOISyR9AcVnrxQGbWyViTpvyXdEkL4YwjhSAjhHyGEf5SwfcXkskBCCPskPSrpqmZ3f0VSYwhhZfbxniw/TdIoSd8ys3Gl7svMPi5pvqQfq7DApkiaa2ads/z7ZvZUC2Pcb2Z7JTVK2ijp6VLngdLV0Do5+lVv033nlDoP+NTKWjGzdpKGSOqc/ahzg5lNM7OTS51HJeSyQDKzJH252Rfuquw+SVIIYWkIYVXW0H+RNEfShY79fE3S0yGEp7OxnpH0kqTLsv3cEUIYnRoghHCdCoeaF0j6H0kHUo9Hq6qFddIoaYuk75pZBzP7XDaHOsc84FcLa6WLpA6SLlfh+WSQpH+XdJNjHmWX2wIJIbwgaauksWbWS9JQSY805WY2zMyeM7OtZrZT0rWSOjl21UOFRbWj6SbpfEldS5zv4WzO3SV9yzEPONTCOgkhHJQ0ToVXtZsk3ajCq+ENjnnAqRbWiqR92X/vDSFsDCFsk3S3svLJm1ydeXAMD6nwKuFsSYtCCJubZY9Imibp0hDCfjO7R/Fv9h6999Xex5r9/3pJvwohTGylObcXvwOptNyvk+wV7buvZs1suZq9+kXF5HqthBDeNrMNKvwuNfdyewSSeUjSCEkT9a//2DpK2p59oz8t6auJcV6RNCH78cEQFQ4Pm8yW9HkzG2lm7czsJDO7yMy6tzQ5Mzs9O93u1GzbkZKukLSkhM8Rxy/X60SSzGxAtk2dmU1R4dXozOI+PbSi3K8VSTMkTc6eXz4s6QYVzuDLnxBCrm+Slkp6W9IHjrr/cklrJe1S4Ys7TdLsLOupQoO3zz7uJelPknar8MutqU2PzfJhkpZJ2q7CIe58SWdm2Q8kLYjMrXO23Q5J/5S0StLEan/N2uItz+sky+/M5rdb0gJJvav9NWurtxpYKx0k3Z89r2zKxj6p2l+3Y90smzAAACXJ+4+wAAA5RYEAAFwoEACACwUCAHChQAAALiW9kdDMOGUrh0IIx7rWUtWwTnJrWwihc7Un0RxrJbeKWiscgQBtx9pqTwA1o6i1QoEAAFwoEACACwUCAHChQAAALnm/nDsA5Ebv3r2j2cUXXxzNfvGLX5RjOlXHEQgAwIUCAQC4UCAAABcKBADgQoEAAFwoEACACwUCAHAp6W+iv5+unHnOOedEs5kzZya37dSpUzSbM2dONJs6dWo027hxY3KfKVyNF0VaEUIYUu1JNFdra+Xxxx+PZpdddlk0q6urK8d0yqmotcIRCADAhQIBALhQIAAAFwoEAOBCgQAAXCgQAIBLTV/OfciQ9Flm3/72t6PZ6NGjo9kpp5ySHLexsTGaTZo0KZqdfvrp0ezqq69O7hN+J5yQfp10zz33RLP6+vpotnZt+s9Gp7ZdtmxZcltUx7nnnpvMx4wZE83WrFnT2tPJPY5AAAAuFAgAwIUCAQC4UCAAABcKBADgQoEAAFxyfxpvx44do9lzzz2X3Hb//v3R7N57741m06dPT477oQ99KJqlTs9cvXp1clyUx+TJk5P58OHDo1nqe92nT5/kuDNmzIhmF1xwQTRLrVuUV0NDQzLv0KFDNLvvvvtaeTb5xxEIAMCFAgEAuFAgAAAXCgQA4EKBAABcKBAAgEvuT+PdtWtXNOvfv39y271790az7du3R7OePXsmx73tttui2cGDB6PZ4sWLk+PC7+STT45m119/fXLbUaNGRbMDBw5Es0984hPJcR9//PFo1qVLl2jW0lV+cXzOPPPMaHbppZcmt928eXM0mzt3bjQbOHBgyxOL2LRpk2s+lcARCADAhQIBALhQIAAAFwoEAOBCgQAAXCgQAIALBQIAcMn9+0BSNmzYkMxT7+eYNGlSNJsyZUpy3NQl5i+55JJotnLlyuS48OvRo0c0e+edd5LbNjY2RrPx48dHs1//+tfJcT/1qU9FM97rUT0TJkyIZu3bp58SU5foX758eTTr27dvyxOLSL0PZPDgwdHszTffdO+zWByBAABcKBAAgAsFAgBwoUAAAC4UCADAhQIBALjU9Gm8/fr1S+Zr1qxxjdvSJZLr6uqi2ZgxY6LZwoULXfNBy044If5a6LTTTktuu2DBgmiW+pMBL774YnLcv/71r8kc1XHxxRe7t/36178ezVKX6J83b15y3NQp/jfddFM0u+GGG6LZ9773veQ+WwNHIAAAFwoEAOBCgQAAXCgQAIALBQIAcKFAAAAuNX0a7549e5L5ddddF82ef/75aDZgwIDkuA8//HA0e+KJJ5LbojxWr14dzb75zW8mt02to9TVlStxtVO0vj59+ri3TZ2qu2TJkmiWugKwJN1xxx2u+bz99tuu7VoLRyAAABcKBADgQoEAAFwoEACACwUCAHChQAAALhQIAMDFQgjFP9is+Acf5eqrr45mN998czSbO3duNPvlL3+Z3Oe2bdui2bXXXhvNUu8fkaQ33ngjmqUuFb1v377kuF4hBCvLwE7Hs07y5m9/+1s0Gz9+fHLbl19+ubWnc7xWhBCGVHsSzVVjraQu3596309LNmzYEM1Sf25Akrp16xbN1q1bF82GDIl/O7du3ZrcZwuKWiscgQAAXCgQAIALBQIAcKFAAAAuFAgAwIUCAQC4VOw03rfeeiuaHThwIJpNnz49mvXv3z+5z5EjR0az1Od9++23J8f9+c9/Hs22b9+e3LYcOI33+AwcODCa/e53v4tmZ511VnLcQ4cOuedUJpzGK2nQoEHR7NFHH01u27t3b9c+N27cmMyfeeaZaHbjjTdGs9Tz6nHiNF4AQPlQIAAAFwoEAOBCgQAAXCgQAIALBQIAcGlfqR299tpr0WzYsGHRbNSoUdGspVNmGxoaotmcOXOi2ZtvvpkcF+8vqdO9lyxZEs1yeJouivDKK69Es09+8pPJbb/xjW9Es7q6umg2a9as5LjVOP2/NXAEAgBwoUAAAC4UCADAhQIBALhQIAAAFwoEAOBSsdN4zzvvvErtCihJu3btotnZZ58dzdq3T//z4TTf2nPw4MFknroSd1vEEQgAwIUCAQC4UCAAABcKBADgQoEAAFwoEACACwUCAHCxEELxDzYr/sGomBCCVXsOzbFOcmtFCGFItSfRHGslt4paKxyBAABcKBAAgAsFAgBwoUAAAC4UCADAhQIBALiUejn3bZLWlmMicOtR7QkcA+skn1grKFZRa6Wk94EAANCEH2EBAFwoEACACwUCAHChQAAALhQIAMCFAgEAuFAgAAAXCgQA4EKBAABc/h/FRgl2H5cvigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying samples of data\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.imshow(test_input[i][1], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Value: {}\".format(test_classes[i][1]))  \n",
    "  plt.tight_layout()\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First neural net\n",
    "Train the model on all the 2000 images in train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    dlc_practical_prologue.generate_pair_sets(size)\n",
    "train_input, train_target, train_classes = Variable(train_input), Variable(train_target), Variable((train_classes))\n",
    "test_input, test_target, test_classes = Variable(test_input), Variable(test_target), Variable(test_classes)\n",
    "\n",
    "my_train_input = train_input.reshape([2*size,196])\n",
    "my_train_classes = train_classes.reshape([2*size])\n",
    "\n",
    "my_train_input1 = train_input[:,0,:]\n",
    "my_train_input2 = train_input[:,1,:]\n",
    "my_train_classes1 = train_classes[0:size,0]\n",
    "my_train_classes2 = train_classes[0:size,1]\n",
    "\n",
    "my_test_input1 = test_input[:,0,:]\n",
    "my_test_input2 = test_input[:,1,:]\n",
    "my_test_classes1 = test_classes[0:size,0]\n",
    "my_test_classes2 = test_classes[0:size,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epoch\n",
    "num_epochs = 25\n",
    "# batch size to compute mini-batch\n",
    "batch_size = 100\n",
    "# number of pixels in the image \n",
    "input_size = 196\n",
    "# number of possible digit: 0 to 9 \n",
    "num_class = 2\n",
    "# small step to find a minima\n",
    "learning_rate = 0.001\n",
    "# hidden size\n",
    "hidden_size = 50\n",
    "# drop out\n",
    "dropout_p = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_based_on_imgs(model_, my_test_input1_, my_test_input2_, test_target_):\n",
    "    total = my_test_input1_.size(0)\n",
    "    out1, out2, result = model_(my_test_input1_, my_test_input2_, total)\n",
    "\n",
    "    _, predictions1 = torch.max(out1.data, 1)\n",
    "    _, predictions2 = torch.max(out2.data, 1)\n",
    "    predictions = (predictions1 <= predictions2).long()\n",
    "\n",
    "    well_predicted_count = (predictions == test_target_).sum().item()\n",
    "\n",
    "    return 1 - well_predicted_count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_based_on_result(model_, my_test_input1_, my_test_input2_, test_target_):\n",
    "    total = my_test_input1_.size(0)\n",
    "    out1, out2, result = model_(my_test_input1_, my_test_input2_, total)\n",
    "    _, predictions = torch.max(result.data, 1)\n",
    "    well_predicted_count = (predictions == test_target_).sum().item()\n",
    "    return 1 - well_predicted_count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_, my_train_input1_, my_train_input2_, my_test_classes1, my_test_classes2, train_target_, criterion_, optimizer_,num_epochs_,batch_size_):\n",
    "\n",
    "    train_error_based_on_imgs = []\n",
    "    train_error_based_on_result = []\n",
    "    test_error_based_on_imgs = []\n",
    "    test_error_based_on_result = []\n",
    "    # train function\n",
    "    \n",
    "    lambda_ = lambda epoch: 0.95 ** epoch\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer_, lr_lambda=lambda_)\n",
    "    \n",
    "    for epoch in range(1, num_epochs_+1):\n",
    "        for i in range(int(len(my_train_input1_)/batch_size_)):  \n",
    "            # Move tensors to the configured device\n",
    "            images1 = my_train_input1_.narrow(0,i*batch_size_,batch_size_)\n",
    "            images2 = my_train_input2_.narrow(0,i*batch_size_,batch_size_)\n",
    "            labels1 = my_test_classes1.narrow(0,i*batch_size_,batch_size_)\n",
    "            labels2 = my_test_classes2.narrow(0,i*batch_size_,batch_size_)\n",
    "            target_labels = train_target_.narrow(0,i*batch_size_,batch_size_)\n",
    "            \n",
    "            # Forward pass\n",
    "            out1, out2, result = model_(images1, images2, batch_size_)\n",
    "\n",
    "            loss1 = criterion_(out1, labels1)\n",
    "            loss2 = criterion_(out2, labels2)\n",
    "            loss3 = criterion_(result, target_labels)\n",
    "            real_loss = loss1 + loss2 + loss3\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer_.zero_grad()\n",
    "            real_loss.backward()\n",
    "            optimizer_.step()            \n",
    "\n",
    "\n",
    "        scheduler.step()\n",
    "    train_error_based_on_imgs.append(test_accuracy_based_on_imgs(model_, my_train_input1_, my_train_input2_, train_target))\n",
    "    train_error_based_on_result.append(test_accuracy_based_on_result(model_, my_train_input1_, my_train_input2_, train_target))\n",
    "    test_error_based_on_imgs.append(test_accuracy_based_on_imgs(model_, my_test_input1, my_test_input2, test_target))\n",
    "    test_error_based_on_result.append(test_accuracy_based_on_result(model_, my_test_input1, my_test_input2, test_target))\n",
    "\n",
    "    if(epoch == 25):    \n",
    "        print ('Loss: {:.4f} on epoch: {}, train error based on imgs and result: {:.5f}, {:.5f}; test error: {:.5f}, {:.5f}'.format(real_loss.item(),epoch,train_error_based_on_imgs[-1],train_error_based_on_result[-1],test_error_based_on_imgs[-1],test_error_based_on_result[-1]))\n",
    "    return train_error_based_on_imgs, train_error_based_on_result, test_error_based_on_imgs, test_error_based_on_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6917 on epoch: 25, train error based on imgs and result: 0.04600, 0.21300; test error: 0.10400, 0.26600\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_class):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU() \n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)  \n",
    "        self.layer3 = nn.Linear(hidden_size, 10) \n",
    "        \n",
    "        self.layer1_comp = nn.Linear(20, 200) \n",
    "        self.layer2_comp = nn.Linear(200, 200)  \n",
    "        self.layer3_comp = nn.Linear(200, 2)\n",
    "    \n",
    "    def forward(self, img1, img2, batch_size_images):\n",
    "        img1 = img1.reshape(batch_size_images,196)\n",
    "        out1 = self.layer1(img1)\n",
    "        out1 = self.relu(out1)\n",
    "        out1 = self.layer2(out1)\n",
    "        out1 = self.relu(out1)\n",
    "        out1 = self.layer3(out1)\n",
    "        \n",
    "        img2 = img2.reshape(batch_size_images,196)\n",
    "        out2 = self.layer1(img2)\n",
    "        out2 = self.relu(out2)\n",
    "        out2 = self.layer2(out2)\n",
    "        out2 = self.relu(out2)\n",
    "        out2 = self.layer3(out2)\n",
    "\n",
    "        result = torch.cat((out1,out2), dim=1, out=None)\n",
    "        \n",
    "        result = self.layer1_comp(result)\n",
    "        result = self.relu(result)\n",
    "        result = self.layer2_comp(result)\n",
    "        result = self.relu(result)\n",
    "        result = self.layer3_comp(result)\n",
    "        \n",
    "        return out1, out2, result\n",
    "  \n",
    "# creating neural net\n",
    "model = NeuralNet(input_size, hidden_size, num_class)\n",
    "\n",
    "# CrossEntropyLoss and optimizer which minimize loss with learning rate step\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) \n",
    "\n",
    "train_error_based_on_imgs, train_error_based_on_result, test_error_based_on_imgs, test_error_based_on_result = train_model(model, my_train_input1, my_train_input2, my_train_classes1, my_train_classes2, train_target, criterion, optimizer, num_epochs, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.04900, 0.07500\n",
      "Loss: 0.0064 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.06100, 0.08800\n",
      "Loss: 0.0039 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.06200, 0.09100\n",
      "Loss: 0.0176 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.06300, 0.08100\n",
      "Loss: 0.0008 on epoch: 25, train error based on imgs and result: 0.00100, 0.00000; test error: 0.06300, 0.07500\n",
      "Loss: 0.0000 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.05400, 0.07800\n",
      "Loss: 0.0000 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.06600, 0.09200\n",
      "Loss: 0.0002 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.06500, 0.09000\n",
      "Loss: 0.0002 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.06400, 0.08200\n",
      "Loss: 0.0001 on epoch: 25, train error based on imgs and result: 0.00000, 0.00000; test error: 0.06100, 0.08300\n"
     ]
    }
   ],
   "source": [
    "train_img = []\n",
    "train_comp = []\n",
    "\n",
    "test_img = []\n",
    "test_comp = []\n",
    "\n",
    "for i in range(10):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    dlc_practical_prologue.generate_pair_sets(size)\n",
    "    train_input, train_target, train_classes = Variable(train_input), Variable(train_target), Variable((train_classes))\n",
    "    test_input, test_target, test_classes = Variable(test_input), Variable(test_target), Variable(test_classes)\n",
    "\n",
    "    my_train_input = train_input.reshape([2*size,196])\n",
    "    my_train_classes = train_classes.reshape([2*size])\n",
    "\n",
    "    my_train_input1 = train_input[:,0,:]\n",
    "    my_train_input2 = train_input[:,1,:]\n",
    "    my_train_classes1 = train_classes[0:size,0]\n",
    "    my_train_classes2 = train_classes[0:size,1]\n",
    "\n",
    "    my_test_input1 = test_input[:,0,:]\n",
    "    my_test_input2 = test_input[:,1,:]\n",
    "    my_test_classes1 = test_classes[0:size,0]\n",
    "    my_test_classes2 = test_classes[0:size,1]\n",
    "    # creating neural net\n",
    "    model = NeuralNet(input_size, hidden_size, num_class)\n",
    "\n",
    "    # CrossEntropyLoss and optimizer which minimize loss with learning rate step\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) \n",
    "\n",
    "    train_error_based_on_imgs, train_error_based_on_result, test_error_based_on_imgs, test_error_based_on_result = train_model(model, my_train_input1, my_train_input2, my_train_classes1, my_train_classes2, train_target, criterion, optimizer, num_epochs, 1)\n",
    "    train_img.append(train_error_based_on_imgs)\n",
    "    train_comp.append(train_error_based_on_result)\n",
    "    test_img.append(test_error_based_on_imgs)\n",
    "    test_comp.append(test_error_based_on_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005015974481593748\n",
      "0.006119640512317702\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.std(test_img))\n",
    "print(np.std(test_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0608\n",
      "0.08349999999999996\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(test_img))\n",
    "print(np.mean(test_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_error_based_on_imgs, 'r', train_error_based_on_result, 'r--', test_error_based_on_imgs, 'b', test_error_based_on_result, 'b--')\n",
    "plt.ylabel('some numbers')\n",
    "plt.title(\"Train error in red, test error in blue over the epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}\".format(1-min(test_error_based_on_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
